{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf4a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-12 12:08:14 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from cs336_alignment.evaluate import EvalEntry\n",
    "with open(\"../data/gsm8k_eval_results.pkl\", \"rb\") as f:\n",
    "    results: list[EvalEntry] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05db8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries with negative reward: 981\n",
      "Prompt:\n",
      "Tim grows 5 trees.  Each year he collects 6 lemons from each tree.  How many lemons does he get in a decade?\n",
      "Answer:\n",
      "----------------------------------------\n",
      "Generated Response:\n",
      " 6000\n",
      "Explanation: 5 trees x 6 lemons per tree x 10 years = 300 lemons per year x 10 years = 3000 lemons per decade x 2 decades = 6000 lemons.\n",
      "----------------------------------------\n",
      "Ground Truth:\n",
      "He gets 5*6=<<5*6=30>>30 lemons per year\n",
      "So he gets 30*10=<<30*10=300>>300 lemons in a decade\n",
      "#### 300\n",
      "----------------------------------------\n",
      "Reward Info:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "all_entries = list(filter(lambda x: x.reward == 0, results))\n",
    "print(f\"Total entries with negative reward: {len(all_entries)}\")\n",
    "entry = sample(all_entries, 1)[0]\n",
    "print(\"Prompt:\")\n",
    "print(entry.prompt)\n",
    "print(\"-\" * 40)\n",
    "print(\"Generated Response:\")\n",
    "print(entry.response)\n",
    "print(\"-\" * 40)\n",
    "print(\"Ground Truth:\")\n",
    "print(entry.ground_truth)\n",
    "print(\"-\" * 40)\n",
    "print(\"Reward Info:\")\n",
    "print(entry.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3cee93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from cs336_alignment.evaluate import EvalEntry\n",
    "with open(\"../data/mmlu_eval_results.pkl\", \"rb\") as f:\n",
    "    results: list[EvalEntry] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0ddd919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries with negative reward: 14042\n",
      "Prompt:\n",
      "# Instruction\n",
      "Below is a list of conversations between a human and an AI assistant (you).\n",
      "Users place their queries under \"# Query:\", and your responses are under \"# Answer:\".\n",
      "You are a helpful, respectful, and honest assistant.\n",
      "You should always answer as helpfully as possible while ensuring safety.\n",
      "Your answers should be well-structured and provide detailed information. They should also have an engaging tone.\n",
      "Your responses must not contain any fake, harmful, unethical, racist, sexist, toxic, dangerous, or illegal content, even if it may be helpful.\n",
      "Your response must be socially responsible, and thus you can reject to answer some controversial topics.\n",
      "\n",
      "# Query:\n",
      "```Answer the following multiple choice question about professional_psychology. Respond with a single sentence of the form \"The correct answer is _\", filling the blank with the letter corresponding to the correct answer (i.e., A, B, C or D).\n",
      "    \n",
      "Question: A student has recently completed a dissertation and is submitting a draft for publication. The studentâ€™s advisor contributed by assisting with data analysis and writing a major part of the first publication draft. If the manuscript is published, the student should receive\n",
      "A. first authorship with the advisor as second author\n",
      "B. firs authorship with the advisor receiving no acknowledgment\n",
      "C. first authorship with the advisor receiving acknowledgment in a footnote\n",
      "D. second authorship with the advisor as first author\n",
      "Answer:```\n",
      "\n",
      "# Answer:\n",
      "```\n",
      "----------------------------------------\n",
      "Generated Response:\n",
      "The correct answer is A.```\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Ground Truth:\n",
      "0\n",
      "----------------------------------------\n",
      "Reward Info:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "all_entries = list(filter(lambda x: x.reward == 0, results))\n",
    "print(f\"Total entries with negative reward: {len(all_entries)}\")\n",
    "entry = sample(all_entries, 1)[0]\n",
    "print(\"Prompt:\")\n",
    "print(entry.prompt)\n",
    "print(\"-\" * 40)\n",
    "print(\"Generated Response:\")\n",
    "print(entry.response)\n",
    "print(\"-\" * 40)\n",
    "print(\"Ground Truth:\")\n",
    "print(entry.ground_truth)\n",
    "print(\"-\" * 40)\n",
    "print(\"Reward Info:\")\n",
    "print(entry.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "558d577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated accuracy: 5263/14042 = 0.3748\n",
      "Failed count: 5883/14042 = 0.4190\n"
     ]
    }
   ],
   "source": [
    "from cs336_alignment.evaluate import extract_mmlu_answer\n",
    "count = 0\n",
    "failed_count = 0\n",
    "for entry in results:\n",
    "    answer = extract_mmlu_answer(entry.response)\n",
    "    if answer is None:\n",
    "        failed_count += 1\n",
    "        continue\n",
    "    if answer == \"A\":\n",
    "        answer = \"0\"\n",
    "    elif answer == \"B\":\n",
    "        answer = \"1\"\n",
    "    elif answer == \"C\":\n",
    "        answer = \"2\"\n",
    "    elif answer == \"D\":\n",
    "        answer = \"3\"\n",
    "    if answer == str(entry.ground_truth):\n",
    "        entry.reward = 1\n",
    "        count += 1\n",
    "print(f\"Updated accuracy: {count}/{len(results)} = {count / len(results):.4f}\")\n",
    "print(f\"Failed count: {failed_count}/{len(results)} = {failed_count / len(results):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d08e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries with positive reward: 0\n"
     ]
    }
   ],
   "source": [
    "all_entries = list(filter(lambda x: x.reward == 1, results))\n",
    "print(f\"Total entries with positive reward: {len(all_entries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
