{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf4a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-12 12:08:14 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from cs336_alignment.evaluate import EvalEntry\n",
    "with open(\"../data/gsm8k_eval_results.pkl\", \"rb\") as f:\n",
    "    results: list[EvalEntry] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05db8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries with negative reward: 981\n",
      "Prompt:\n",
      "Tim grows 5 trees.  Each year he collects 6 lemons from each tree.  How many lemons does he get in a decade?\n",
      "Answer:\n",
      "----------------------------------------\n",
      "Generated Response:\n",
      " 6000\n",
      "Explanation: 5 trees x 6 lemons per tree x 10 years = 300 lemons per year x 10 years = 3000 lemons per decade x 2 decades = 6000 lemons.\n",
      "----------------------------------------\n",
      "Ground Truth:\n",
      "He gets 5*6=<<5*6=30>>30 lemons per year\n",
      "So he gets 30*10=<<30*10=300>>300 lemons in a decade\n",
      "#### 300\n",
      "----------------------------------------\n",
      "Reward Info:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "all_entries = list(filter(lambda x: x.reward == 0, results))\n",
    "print(f\"Total entries with negative reward: {len(all_entries)}\")\n",
    "entry = sample(all_entries, 1)[0]\n",
    "print(\"Prompt:\")\n",
    "print(entry.prompt)\n",
    "print(\"-\" * 40)\n",
    "print(\"Generated Response:\")\n",
    "print(entry.response)\n",
    "print(\"-\" * 40)\n",
    "print(\"Ground Truth:\")\n",
    "print(entry.ground_truth)\n",
    "print(\"-\" * 40)\n",
    "print(\"Reward Info:\")\n",
    "print(entry.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cee93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from cs336_alignment.evaluate import EvalEntry\n",
    "with open(\"../data/mmlu_eval_results.pkl\", \"rb\") as f:\n",
    "    results: list[EvalEntry] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ddd919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries with negative reward: 45\n",
      "Prompt:\n",
      "# Instruction\n",
      "Below is a list of conversations between a human and an AI assistant (you).\n",
      "Users place their queries under \"# Query:\", and your responses are under \"# Answer:\".\n",
      "You are a helpful, respectful, and honest assistant.\n",
      "You should always answer as helpfully as possible while ensuring safety.\n",
      "Your answers should be well-structured and provide detailed information. They should also have an engaging tone.\n",
      "Your responses must not contain any fake, harmful, unethical, racist, sexist, toxic, dangerous, or illegal content, even if it may be helpful.\n",
      "Your response must be socially responsible, and thus you can reject to answer some controversial topics.\n",
      "\n",
      "# Query:\n",
      "```Answer the following multiple choice question about high_school_european_history. Respond with a single sentence of the form \"The correct answer is _\", filling the blank with the letter corresponding to the correct answer (i.e., A, B, C or D).\n",
      "    \n",
      "Question: This question refers to the following information.\n",
      "\"In 1500 that work appeared which Erasmus had written after his misfortune at Dover, and had dedicated to Mountjoy, the Adagiorum Collectanea. It was a collection of about eight hundred proverbial sayings drawn from the Latin authors of antiquity and elucidated for the use of those who aspired to write an elegant Latin style. In the dedication Erasmus pointed out the profit an author may derive, both in ornamenting his style and in strengthening his argumentation, from having at his disposal a good supply of sentences hallowed by their antiquity. He proposes to offer such a help to his readers. What he actually gave was much more. He familiarized a much wider circle than the earlier humanists had reached with the spirit of antiquity.\n",
      "Until this time the humanists had, to some extent, monopolized the treasures of classic culture, in order to parade their knowledge of which the multitude remained destitute, and so to become strange prodigies of learning and elegance. With his irresistible need of teaching and his sincere love for humanity and its general culture, Erasmus introduced the classic spirit, in so far as it could be reflected in the soul of a sixteenth-century Christian, among the people. Not he alone; but none more extensively and more effectively. Not among all the people, it is true, for by writing in Latin he limited his direct influence to the educated classes, which in those days were the upper classes.\n",
      "Erasmus made current the classic spirit. Humanism ceased to be the exclusive privilege of a few. According to Beatus Rhenanus he had been reproached by some humanists, when about to publish the Adagia, for divulging the mysteries of their craft. But he desired that the book of antiquity should be open to all.\"\n",
      "Johan Huizinga, twentieth-century Dutch philosopher, Erasmus and the Age of Reformation, 1924\n",
      "What was the primary impact of \"Humanism ceas[ing] to be the exclusive privilege of the few\"?\n",
      "A. The populous demanded rights from the state.\n",
      "B. People could begin to question the Church on a wider scale.\n",
      "C. Latin replaced many of the vulgar languages throughout Europe.\n",
      "D. European literature stagnated due to widespread interest in the writings of antiquity.\n",
      "Answer:```\n",
      "\n",
      "# Answer:\n",
      "```\n",
      "----------------------------------------\n",
      "Generated Response:\n",
      "The primary impact of \"Humanism ceas[ing] to be the exclusive privilege of the few\" was that people could begin to question the Church on a wider scale. This was because the classic spirit was made available to a wider audience, which allowed for a greater number of people to be exposed to the ideas of antiquity. This in turn led to a greater number of people questioning the Church and its teachings, which ultimately led to the Reformation.```\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Ground Truth:\n",
      "1\n",
      "----------------------------------------\n",
      "Reward Info:\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "all_entries = list(filter(lambda x: x.reward == -1.0, results))\n",
    "print(f\"Total entries with negative reward: {len(all_entries)}\")\n",
    "entry = sample(all_entries, 1)[0]\n",
    "print(\"Prompt:\")\n",
    "print(entry.prompt)\n",
    "print(\"-\" * 40)\n",
    "print(\"Generated Response:\")\n",
    "print(entry.response)\n",
    "print(\"-\" * 40)\n",
    "print(\"Ground Truth:\")\n",
    "print(entry.ground_truth)\n",
    "print(\"-\" * 40)\n",
    "print(\"Reward Info:\")\n",
    "print(entry.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558d577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated accuracy: 8247/14042 = 0.5873\n",
      "Failed count: 45/14042 = 0.0032\n"
     ]
    }
   ],
   "source": [
    "from cs336_alignment.evaluate import extract_mmlu_answer\n",
    "count = 0\n",
    "failed_count = 0\n",
    "for entry in results:\n",
    "    answer = extract_mmlu_answer(entry.response)\n",
    "    if answer is None:\n",
    "        failed_count += 1\n",
    "        entry.reward = -1.0\n",
    "        continue\n",
    "    if answer == \"A\":\n",
    "        answer = \"0\"\n",
    "    elif answer == \"B\":\n",
    "        answer = \"1\"\n",
    "    elif answer == \"C\":\n",
    "        answer = \"2\"\n",
    "    elif answer == \"D\":\n",
    "        answer = \"3\"\n",
    "    if answer == str(entry.ground_truth):\n",
    "        entry.reward = 1\n",
    "        count += 1\n",
    "print(f\"Updated accuracy: {count}/{len(results)} = {count / len(results):.4f}\")\n",
    "print(f\"Failed count: {failed_count}/{len(results)} = {failed_count / len(results):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d08e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct answer is B.```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(entry.response)\n",
    "extract_mmlu_answer(entry.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
