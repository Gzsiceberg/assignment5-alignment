{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf4a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
      "User: {0}\n",
      "Assistant: <think>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "train: datasets.Dataset = ds[\"train\"]\n",
    "prompt_templ = \"\"\"A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
    "User: {0}\n",
    "Assistant: <think>\"\"\"\n",
    "print(prompt_templ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c199f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_alignment.math_baseline import extract_answer\n",
    "prompts = []\n",
    "ground_truths = []\n",
    "for t, data in enumerate(train):\n",
    "    question = data[\"question\"]\n",
    "    answer_text = data[\"answer\"]\n",
    "    answer = extract_answer(answer_text)\n",
    "    assert answer is not None, f\"Could not extract answer from: {answer_text}\"\n",
    "    full_prompt = prompt_templ.format(question)\n",
    "    prompts.append(full_prompt)\n",
    "    ground_truths.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aef9369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Rica's group won in a dance competition. She got 3/8 of the prize money. From Rica's prize money, she spent 1/5 of it and is now left with $300. How much was the prize money that her group won?\n",
      "--------------------\n",
      "Ground truth answer:\n",
      "1000\n",
      "--------------------\n",
      "Answer Text:\n",
      "Rica is left with 1 - 1/5 = 4/5 of her prize money which is equal to $300.\n",
      "Since 4/5 is worth $300, then 1/5 is worth $300/4 = $75.\n",
      "So, Rica got $75 x 5 = $375 from their prize money which is 3/8 of the total prize.\n",
      "Since 3/8 is equal to $375, then 1/8 is worth $375/3 = $125.\n",
      "So, the total prize money is $125 x 8 = $<<125*8=1000>>1000.\n",
      "#### 1000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(0, len(prompts) - 1)\n",
    "print(\"Question:\")\n",
    "print(train[index][\"question\"])\n",
    "print(\"-\" * 20)\n",
    "print(\"Ground truth answer:\")\n",
    "print(ground_truths[index])\n",
    "print(\"-\" * 20)\n",
    "print(\"Answer Text:\")\n",
    "print(train[index][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d943bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/math_baseline_eval_results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0153712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
      "User: A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "Assistant: <think>\n",
      "--------------------\n",
      "Completion:\n",
      " Let the number of people on the first ship be x. Then the number of people on the second ship is 2x and the number of people on the third ship is 4x. The total number of people on the three ships is 847, so x + 2x + 4x = 847. Simplifying, we get 7x = 847, so x = 121. Therefore, there were 121 people on the ship in the first century.</think> <answer> 121</answer>\n",
      "--------------------\n",
      "Ground Truth:\n",
      "121\n",
      "--------------------\n",
      "Reward:\n",
      "{'format_reward': 0.0, 'answer_reward': 0.0, 'reward': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "prompts = results[\"prompts\"]\n",
    "responses = results[\"responses\"]\n",
    "rewards = results[\"rewards\"]\n",
    "ground_truths = results[\"ground_truths\"]\n",
    "\n",
    "index = random.randint(0, len(prompts) - 1)\n",
    "print(\"Prompt:\")\n",
    "print(prompts[index])\n",
    "print(\"-\" * 20)\n",
    "print(\"Response:\")\n",
    "print(responses[index])\n",
    "print(\"-\" * 20)\n",
    "print(\"Ground Truth:\")\n",
    "print(ground_truths[index])\n",
    "print(\"-\" * 20)\n",
    "print(\"Reward:\")\n",
    "print(rewards[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "567f85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, r in enumerate(rewards):\n",
    "    formatted_reward = r[\"format_reward\"]\n",
    "    if formatted_reward > 0:\n",
    "        print(t)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
