{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "train: datasets.Dataset = ds[\"train\"]\n",
    "prompt_templ = \"\"\"A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
    "User: {0}\n",
    "Assistant: <think>\"\"\"\n",
    "print(prompt_templ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_alignment.math_baseline import extract_answer\n",
    "prompts = []\n",
    "ground_truths = []\n",
    "for t, data in enumerate(train):\n",
    "    question = data[\"question\"]\n",
    "    answer_text = data[\"answer\"]\n",
    "    answer = extract_answer(answer_text)\n",
    "    assert answer is not None, f\"Could not extract answer from: {answer_text}\"\n",
    "    full_prompt = prompt_templ.format(question)\n",
    "    prompts.append(full_prompt)\n",
    "    ground_truths.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index = random.randint(0, len(prompts) - 1)\n",
    "print(\"Question:\")\n",
    "print(train[index][\"question\"])\n",
    "print(\"-\" * 20)\n",
    "print(\"Ground truth answer:\")\n",
    "print(ground_truths[index])\n",
    "print(\"-\" * 20)\n",
    "print(\"Answer Text:\")\n",
    "print(train[index][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d943bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-04 23:49:46 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from cs336_alignment.math_baseline import EvalEntry\n",
    "with open(\"../data/math_baseline_eval_results.pkl\", \"rb\") as f:\n",
    "    results: list[EvalEntry] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0153712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
      "User: Compute: $\\frac{1}{5} + \\frac{2}{5} + \\frac{3}{5} + \\dots + \\frac{9}{5} + \\frac{10}{5}$.\n",
      "Assistant: <think>\n",
      "--------------------\n",
      "Response:\n",
      " We are using the arithmetic progression formula to find the total sums: <think> <answer> 9/5*2 </answer>\n",
      "--------------------\n",
      "Ground Truth:\n",
      "This is a sum of an arithmetic series. The formula for the sum of an arithmetic series is given by $\\frac{n}{2}(a + l)$, where $n$ is the number of terms, $a$ is the first term, and $l$ is the last term.\n",
      "\n",
      "Here, $n = 10$, $a = \\frac{1}{5}$, and $l = \\frac{10}{5}$.\n",
      "\n",
      "Plugging these values into the formula, we get:\n",
      "$$\\frac{10}{2} \\left( \\frac{1}{5} + \\frac{10}{5} \\right) = 5 \\left( \\frac{11}{5} \\right) = 11.$$So the sum of the series $\\frac{1}{5} + \\frac{2}{5} + \\frac{3}{5} + \\dots + \\frac{9}{5} + \\frac{10}{5}$ is 11. The answer is: $11$\n",
      "--------------------\n",
      "Reward:\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Format Reward looks correct, only one issue is that therre are some cases \\nwhere <think/> something <answer> answer </answer> is not satisfied. \\nWe can improve the format reward by checking for this condition.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from cs336_alignment.math_baseline import EvalEntry\n",
    "total_samples = len(results)\n",
    "index = random.randint(0, total_samples - 1)\n",
    "eval_entry: EvalEntry = results[index]\n",
    "if eval_entry.reward <= 0 and eval_entry.format_reward <= 0:\n",
    "    print(\"Prompt:\")\n",
    "    print(eval_entry.prompt)\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Response:\")\n",
    "    print(eval_entry.response)\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Ground Truth:\")\n",
    "    print(eval_entry.ground_truth)\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Reward:\")\n",
    "    print(eval_entry.reward)\n",
    "\n",
    "\"\"\"Format Reward looks correct, only one issue is that therre are some cases \n",
    "where <think/> something <answer> answer </answer> is not satisfied. \n",
    "We can improve the format reward by checking for this condition.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567f85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 128\n",
      "Correct samples: 34, percent: 0.2656\n",
      "Format correct samples: 0, percent: 0.0000\n",
      "Wrong samples: 94, percent: 0.7344\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "format_correct_count = 0\n",
    "wrong_count = 0\n",
    "total_count = len(results)\n",
    "for t, entry in enumerate(results):\n",
    "    if entry.reward > 0:\n",
    "        correct_count += 1\n",
    "    elif entry.format_reward > 0:\n",
    "        format_correct_count += 1\n",
    "    else:\n",
    "        wrong_count += 1\n",
    "print(f\"Total samples: {len(results)}\")\n",
    "print(f\"Correct samples: {correct_count}, percent: {correct_count / total_count:.4f}\")\n",
    "print(f\"Format correct samples: {format_correct_count}, percent: {format_correct_count / total_count:.4f}\")\n",
    "print(f\"Wrong samples: {wrong_count}, percent: {wrong_count / total_count:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c396be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total such samples: 34\n",
      "Prompt:\n",
      "A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
      "User: Place each of the digits 6, 7, 8 and 9 in exactly one square to make the smallest possible product. What is this product? [asy]draw((0,.5)--(10,.5),linewidth(1));\n",
      "draw((4,1)--(6,1)--(6,3)--(4,3)--(4,1),linewidth(1));\n",
      "draw((7,1)--(9,1)--(9,3)--(7,3)--(7,1),linewidth(1));\n",
      "draw((7,4)--(9,4)--(9,6)--(7,6)--(7,4),linewidth(1));\n",
      "draw((4,4)--(6,4)--(6,6)--(4,6)--(4,4),linewidth(1));\n",
      "draw((1,3)--(2,4),linewidth(1));\n",
      "draw((1,4)--(2,3),linewidth(1)); [/asy]\n",
      "Assistant: <think>\n",
      "--------------------\n",
      "Response:\n",
      " independent variables </think> <thought> functions or relations </think> <think> ability to identify variables </think> <think> ability to identify functions </think> <think> to write a function name from variables </think> <answer> x87 </answer>\n",
      "[]\n",
      "--------------------\n",
      "Ground Truth:\n",
      "The product is the product of two 2-digit numbers. The smaller the numbers, the smaller the product. Hence, we want to place the smallest digits 6, 7, 8 and 9 in the two 2-digit numbers to minimize their product. We place 6 and 7 in the tens place of the two numbers and 8 and 9 in the ones place. This gives us the numbers 68 and 79.\n",
      "To find the minimum product, multiply these two numbers: $$68 \\times 79 = 5372.$$\n",
      "The smallest possible product is therefore 5372. The answer is: $\\boxed{5372}$\n",
      "answer=5372\n",
      "--------------------\n",
      "Reward:\n",
      "reward: 1.0, format_reward: 1.0, answer_reward_v2: 0.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from math_verify import parse\n",
    "from cs336_alignment.extract import extract_ans\n",
    "all_indexes = []\n",
    "for t, entry in enumerate(results):\n",
    "    if entry.format_reward > 0 and entry.reward > 0:\n",
    "        all_indexes.append(t)\n",
    "\n",
    "print(f\"Total such samples: {len(all_indexes)}\")\n",
    "index = random.choice(all_indexes)\n",
    "entry = results[index]\n",
    "format_rewards = entry.format_reward\n",
    "print(\"Prompt:\")\n",
    "print(entry.prompt)\n",
    "print(\"-\" * 20)\n",
    "print(\"Response:\")\n",
    "print(entry.response)\n",
    "print(parse(entry.response))\n",
    "print(\"-\" * 20)\n",
    "print(\"Ground Truth:\")\n",
    "print(entry.ground_truth)\n",
    "print(f\"answer={extract_ans(entry.ground_truth, True)}\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Reward:\")\n",
    "print(f\"reward: {entry.reward}, format_reward: {entry.format_reward}, answer_reward_v2: {entry.answer_reward_v2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3066de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp_answer: [], ground truth: [5372, '5372'], is_correct: 0.0\n",
      "Reward: {'format_reward': 1.0, 'answer_reward': 1.0, 'reward': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from cs336_alignment.drgrpo_grader import r1_zero_reward_fn, _normalize\n",
    "from math_verify import parse, verify, LatexExtractionConfig, ExprExtractionConfig\n",
    "\n",
    "resp_answer = parse(entry.response)\n",
    "gt_answer = parse(entry.ground_truth)\n",
    "is_correct = verify(resp_answer, gt_answer)\n",
    "print(f\"resp_answer: {resp_answer}, ground truth: {gt_answer}, is_correct: {1.0 if is_correct else 0.0}\")\n",
    "\n",
    "reward = r1_zero_reward_fn(entry.response, entry.ground_truth, False)\n",
    "print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9c132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "ds = load_dataset(\"hkust-nlp/dart-math-uniform\")\n",
    "train: datasets.Dataset = ds[\"train\"]\n",
    "prompt_templ = \"\"\"A conversation between User and Assistant. The User asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the User with the answer. The reasoning process is enclosed within <think> </think> and answer is enclosed within <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>.\n",
    "User: {0}\n",
    "Assistant: <think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from cs336_alignment.extract import extract_ans\n",
    "prompts: List[str] = []\n",
    "responses: List[str] = []\n",
    "for t, data in enumerate(train):\n",
    "    question: str = data[\"query\"] # type: ignore\n",
    "    answer_text: str = data[\"response\"] # type: ignore\n",
    "    answer = extract_ans(answer_text, True)\n",
    "    if answer is None:\n",
    "        print(f\"Skipping sample {t} due to no extractable answer.\")\n",
    "        break\n",
    "    full_prompt = prompt_templ.format(question)\n",
    "    prompts.append(full_prompt)\n",
    "    responses.append(f\"{answer_text} </think> <answer> {answer} </answer>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb29a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp_answer: [11/850, '\\\\frac{11}{850}']\n"
     ]
    }
   ],
   "source": [
    "from math_verify import parse, verify\n",
    "import random\n",
    "index = random.randint(0, len(train) - 1)\n",
    "data = train[index]\n",
    "\n",
    "response = data[\"response\"]\n",
    "\n",
    "resp_answer = parse(response)\n",
    "print(f\"resp_answer: {resp_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c9ea89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11/850'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(resp_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bdb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
